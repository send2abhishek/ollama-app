from langchain_ollama import ChatOllama
from langchain_core.output_parsers import StrOutputParser
from langchain_core.prompts import (SystemMessagePromptTemplate,HumanMessagePromptTemplate,ChatPromptTemplate,MessagesPlaceholder)
from langchain_core.runnables.history import RunnableWithMessageHistory
from langchain_community.chat_message_histories import SQLChatMessageHistory
from sqlalchemy import create_engine
from sqlalchemy.engine import Engine
import streamlit as st


st.title("Personal Chatbot")
st.write("Chat anything with me which will remain private to me")



llm = ChatOllama(
    model="llama3.1:latest",
    validate_model_on_init=True,
    temperature=0.8,
    num_predict=256,
)

def get_session_history(session_id):
    engine: Engine = create_engine("sqlite:///chat_history.db")
    return SQLChatMessageHistory(session_id, connection=engine)


# user_id='send2abhishek'




system = SystemMessagePromptTemplate.from_template("You are helpful assistance.")
human = HumanMessagePromptTemplate.from_template("{input}")
message = [system,MessagesPlaceholder(variable_name='history'), human]
prompt = ChatPromptTemplate(messages=message)
chain = prompt | llm | StrOutputParser()
runnable_with_history = RunnableWithMessageHistory(chain,get_session_history,
                                                   input_messages_key='input',
                                                   history_messages_key='history')


def chat_with_llm(session_id,input):
    for output in runnable_with_history.stream({'input': input},config={'configurable':{'session_id':session_id}}):
        yield output


user_id = st.text_input("Enter your User ID","send2abhishek")

if "chat_history" not in st.session_state:
    st.session_state["chat_history"] = []

if st.button("Start New Conversation"):
    st.session_state.chat_history= []
    history = get_session_history(user_id)
    history.clear()


for message in st.session_state.chat_history:
    with st.chat_message(message['role']):
        st.markdown(message['content'])




prompt = st.chat_input("What is up ?")
st.write(prompt)

if prompt:
    st.session_state.chat_history.append({'role': 'user','content': prompt})

    with st.chat_message("user"):
        st.markdown(prompt)


    with st.chat_message("assistant"):
        response = st.write_stream(chat_with_llm(user_id,prompt))

    st.session_state.chat_history.append({'role': 'assistant','content': response})





